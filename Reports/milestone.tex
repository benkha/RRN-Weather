%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title_page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\title{Title page with logo}
%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}

\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Analyzing Information in RNNs}\\[0.5cm] % Name of your university/college
% \textsc{\Large Major Heading}\\[0.5cm] % Major heading such as course name
% \textsc{\large March 19, 2018}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries CS 294-131 Research Project}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.5\textwidth}
\begin{flushleft} \large
\emph{Authors:}\\
Stefan \textsc{Ivanovic} (Freshman) \\% Your name
email: \\
SID: \\
\bigskip
Benjamin \textsc{Kha} (Senior) \\% Your name
email: \\
SID: \\
\bigskip
Vignesh \textsc{Muruganantham} (Senior) \\% Your name
muruvig@berkeley.edu\\
SID: 25390657\\
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Professors:} \\
Trevor \textsc{Darrell} \\% Supervisor's Name
Dawn \textsc{Song} \\% Supervisor's Name
\end{flushright}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

% %----------------------------------------------------------------------------------------
% %	DATE SECTION
% %----------------------------------------------------------------------------------------

% {\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------
% \begin{center}
% 	\includegraphics[scale=0.2]{cal_logo.png}\\[1cm] % Include a department/university logo - this will require the graphicx package
% \end{center}
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}


% \begin{abstract}
% Your abstract.
% \end{abstract}

\section{Problem Definition \& Motivation}

In this project, we are interested in the structures that might arise in neural
networks from an information theoretic perspective. More specifically, we are
interested in the case of possible structures involving fully recurrent neural
networks and mutual information. Our specific subdomain is within the context of
using recurrent neural networks for time series prediction tasks in a continuous
input and output space. Most of the previous work involving recurrent neural
networks are concerned with different applications, usually natural language \cite{text} or
speech recognition \cite{speech}, but there has also been some work involving time series as
well \cite{rnn_time_series, rnn_stocks} and in some other continuous input and
output space settings \cite{text}. Even more specifically, here are 5 questions
we will research in exploring this area as our problem definitions:

\begin{enumerate}
	\item Is there a general direction of information flow within the neural network?
	\item Does the network naturally form structures similar to layers?
	\item Does the concept of an information bottleneck apply in a useful way of fully recurrent neural networks?
	\item Do features such as complexity and mutual information with Y give useful indicators of learning?
	\item Do results from feed forward neural networks about the drift phase and diffusion phase also apply to fully recurrent neural networks?
\end{enumerate}

\section{Related Work \& Comparisons}
% This needs to be changed/added to since this section is directly from the proposal. Probably need to find more sources as well.
We were inspired by the presented work in the class on information theory
\cite{disentangling_representations}, making us research this topic more in
depth. Two important pieces of related work are “Opening the black box of Deep
Neural Networks via Information” by Ravid Schwartz-Ziv and Naftali Tishby
\cite{black_box}, and “Information Theory for Analyzing
Neural Networks” by B\aa rd S\o rng\aa rd \cite{ntnu}. These papers present some
foundational work on using information theory in deep learning research.

The results in “Opening the black box of Deep Neural Networks via Information”
are perfectly sufficient for analyzing feed forward neural networks, however,
there is no analysis of recurrent neural networks. “Information Theory for
Analyzing Neural Networks” does analyze recurrent neural networks, however, it
does not consider the topics we wish to analyze. These topics include fully
recurrent neural networks, analyzing the development of structure in neural
networks (this RNN has a very simple, non-flexible predetermined structure), the
stages of learning in neural networks, and the concept of an information
bottleneck, similar to that discussed in Tishby \& Zaslavsky's paper
\cite{info_bottleneck}.

\section{Approach}
% Make sure to properly make references in this section
We started by using an existing implementation of an RNN used to predict future
temperatures for a certain airport given the temperature in the past. Thus we
have a continuous input and output space for this problem. This was taken from
\cite{weather}. This luckily came with data files containing the results of
their test set given as a .pkl file. Using this, we measured the time delayed
mutual information in the network to see if there was any clear pattern (this
was done using a mutual information estimator for continuous variables
\cite{mutual_info, content_transfer, social_media}).

\section{Current Progress}
So far, we have conducted the analysis we wanted on the given pickled test set
data. We programmed code to save all the relevant data during testing to be used
in our analyses. We programmed an efficient way of processing the data and
calculating the time delayed mutual information between every neuron in the
network (including inputs, outputs, and hidden neurons). We calculated the
entropy of each neuron.
We also calculated non-time-delayed mutual information between the neurons and
subtracted this from the time delayed mutual information. This had the effect of
removing the effects of confounding variables and allowing us to see the
information flow between neurons more effectively.
We then looked to find a pattern for information flow as one would expect in an
RNN. We ended up using two methods. The first method calculates the progression
of a neuron along the network using a directed graph of information flow, and
the second method uses the raw information flow data. We found that generally
the outputs were considered “further along” the network than the hidden neurons,
which were considered “further along” the network than the inputs. We then
created a histogram of the progression along the network for the inputs,
outputs, and hidden neurons. Using these results, it seems there is a general
direction of information flow within the network. However, due to the chaotic
structure of the network, and the only slight existence of a direction of
information flow, we may need to perform more analysis and are not yet sure if
the RNNs form structures similar to layers.
We next looked into the topic of information bottleneck and found that there was
a slight positive correlation between the hidden neurons and the inputs and
outputs, which would be strange if the information bottleneck effect were in
play. One explanation is that some neurons are simply “more important” and take
into account the most significant pattern between the inputs and outputs, but
more analysis is needed here.
We also ran the entire training process on our own machines and are moving
towards performing similar analyses on this data set.


\section{Timeline}
\begin{enumerate}
	\item Complete analyses of how the mutual information with X and Y change
    during training. Also analyze how the gradient mean and standard deviation
    behave during training. Also finish the analysis of the training data. 4/4
	\item Use our analyses to conclude how the concept of an information bottleneck applies to fully recurrent neural networks. Also use our analyses to conclude if the network’s training also splits into a drift phase and diffusion phase. If not, analyze if the networks training has any apparent phases (not necessarily these two). 4/11
	\item Form conclusions about how all of these analyses relate to each other, what results seem the most important, and what would be interesting for other researchers to further look into. 4/18
	\item Complete our paper with information on all important results. 4/23
\end{enumerate}

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}